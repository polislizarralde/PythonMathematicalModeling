{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python 3.11.2\n",
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import json # for pretty printing\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three different data sources. \n",
    "\n",
    "1. The data collected by Bodil corresponds to the plague period.\n",
    "2. The information from the TABVERK database includes the population size for parishes in the posterior years of the plague.\n",
    "3. The geographical information (polygons) for some parishes. This information doesn't correspond to the plague period.\n",
    "\n",
    "Our goal is to create a unique database for our project: Plague spread across Scania, Sweden, from 1710 to 1715."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "script_dir_Appendix6 = os.path.dirname(os.path.abspath(\"Appendix6Bodil.csv\"))\n",
    "script_dir_allParishes = os.path.dirname(os.path.abspath(\"allParishesScania.xlsx\"))\n",
    "\n",
    "# File paths relative to the script directory\n",
    "appendix6_path = os.path.join(script_dir_Appendix6, \"Appendix6Bodil.csv\")\n",
    "allParishes_path = os.path.join(script_dir_allParishes, \"allParishesScania.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read the different data sources (.xlsx, .csv, and .shp files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bodil's data Appendix 6 plague parishes\n",
    "plagueParishesScania = pd.read_csv(appendix6_path, sep=\",\", encoding=\"utf-8\")\n",
    "# All parishes in Scania during the plague period\n",
    "allParishesScania = pd.read_excel(allParishes_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the lowercase to uppercase and checking the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allParishesScania = allParishesScania.apply(\n",
    "    lambda x: x.astype(str).str.upper())\n",
    "plagueParishesScania = plagueParishesScania.apply(\n",
    "    lambda x: x.astype(str).str.upper())\n",
    "type(plagueParishesScania)\n",
    "type(allParishesScania)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allParishesScania.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plagueParishesScania.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the two datasets (allParishesScania and plagueParishesScania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishesScania = pd.merge(\n",
    "    allParishesScania, plagueParishesScania, how='left', on=['ParishName', 'Region'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the new data frame keep all the outbreaks for parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parishesScania.loc[parishesScania['ParishName'] == 'NÄSUM']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function for extracting the names of the parishes in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Names(data: pd.DataFrame, heading:str) -> list:\n",
    "    return data[heading].tolist()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the data frame by region and then get the names of the parishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishesScania_names = get_Names(parishesScania, 'ParishName')\n",
    "len(parishesScania_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishes = allParishesScania.loc[allParishesScania['Region'] == 'SOUTHEAST']\n",
    "southeastParishes_names = get_Names(southeastParishes, 'ParishName')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the census file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "file_name = 'FILE01_FALD.txt'\n",
    "folder_name = 'CensusScania'\n",
    "census_path = os.path.join(os.path.expanduser(\n",
    "    \"~\"), \"Desktop\", folder_name, file_name)\n",
    "\n",
    "censusSweden = pd.read_csv(census_path, sep=';')\n",
    "censusSweden.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#censusSweden.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the names of all columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = censusSweden.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the data only with specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusSweden = pd.read_csv(census_path, sep=';', usecols=[\n",
    "                           'LANGENNMN'  # Standard name of the county for the geographical area in plain text\n",
    "                           , 'GEOIDNMN'  # Standard name of the geographical area in plain text, i.e. not a source name\n",
    "                           , 'GEOIDTYP'  # Type of breakdown of the geographical area  0 =Assembly, 1 = Pastorate, 2 = Other type, 3 = Several parishes, 9 = Part of a parish\n",
    "                           , 'AR'  # Year\n",
    "                           , 'KON'  # 1 = Man  2 = Female. I choose 1 but it could be 2 for the total population\n",
    "                           , 'BEF_TOT'  # Total population at source\n",
    "                           , 'BEF_GENTOT'  # Total population, generated\n",
    "                           ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the census data such that corresponds only to Scania and the first population size registred for each parish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusScania = censusSweden.loc[((censusSweden['LANGENNMN'] == 'KRISTIANSTADS LÄN') | (\n",
    "    censusSweden['LANGENNMN'] == 'MALMÖHUS LÄN')) & (censusSweden['KON'] == 1)]\n",
    "censusScania.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data from Scania only to keep the first population size registered for each parish.\n",
    "This was done following two approaches: the first one by grouping the data by parish name and then selecting the minimum year. The second approach is exhaustively exploring the given DataFrame and keeping the required information in a dictionary. The information required in our case corresponds to the position associated with each parish name and the minimum year, according to the original DataFrame. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "#Group a Pandas DataFrame by a column\n",
    "parish_grp = censusScania.groupby(['GEOIDNMN'])\n",
    "# Get the unique values of a column as a list\n",
    "parish_grp_name = parish_grp['GEOIDNMN'].unique().tolist()\n",
    "#Get the unique values of a column as a list of strings\n",
    "parish_names = [parish_name[0] for parish_name in parish_grp_name]\n",
    "#print(parish_names)\n",
    "\n",
    "popSizeScania = pd.DataFrame()\n",
    "\n",
    "for name in parish_grp_name:\n",
    "    grp_name = parish_grp.get_group(name[0])\n",
    "    popSizeScania = pd.concat(\n",
    "        [popSizeScania, (grp_name[grp_name.AR == grp_name.AR.min()])], axis=0)\n",
    " \n",
    "print(popSizeScania.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "aux_dict = {}\n",
    "popSizeScania = pd.DataFrame() \n",
    "\n",
    "for i in range(len(censusScania)):\n",
    "    name_i = censusScania['GEOIDNMN'].iloc[i]\n",
    "    ar_i = censusScania['AR'].iloc[i]\n",
    "    if name_i in aux_dict:\n",
    "        if ar_i < aux_dict[name_i]['min']:\n",
    "            aux_dict[name_i] = {'min': ar_i, 'position': i}\n",
    "    else:\n",
    "        aux_dict[name_i] = {'min': ar_i, 'position': i}\n",
    "final_positions = [value['position'] for key, value in aux_dict.items()]\n",
    "popSizeScania = censusScania.iloc[final_positions]   \n",
    "print(popSizeScania.shape)            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popSizeScania.loc[popSizeScania['GEOIDNMN'] == 'STORA KÖPINGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popSizeScania.iloc[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popSizeScania_names = get_Names(popSizeScania, 'GEOIDNMN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_strings(data: pd.DataFrame, column: str, list_expr: list[str]) -> pd.DataFrame:\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for expr in list_expr:\n",
    "            data = data.apply(lambda x: x.replace({expr: ''}, regex=True))\n",
    "    else:\n",
    "        for expr in list_expr:\n",
    "            data[column] = data[column].replace({expr: ''}, regex=True)\n",
    "    return data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the geographical information by parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "shapefile_directory = os.path.join(parent_directory, \"MapScaniaSweden\")\n",
    "\n",
    "parishScania_path = os.path.join(shapefile_directory, \"Parishes1720_1890.shp\")\n",
    "parishScaniaMap = gpd.read_file(parishScania_path)\n",
    "selected_columns = ['G_NAME', 'geometry']\n",
    "parishScaniaMap = parishScaniaMap[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishScaniaMap = delete_strings(\n",
    "    parishScaniaMap,'', ['FÖRSAMLING'\n",
    "                      , 'L LÄN'\n",
    "                      , 'S LÄN'\n",
    "                      , 'HELIGA TREFALDIGHETS'\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishScaniaMap.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishScaniaMap_names = get_Names(parishScaniaMap, 'G_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(data: pd.DataFrame, column: pd.Series, name: str):\n",
    "    filt_name = column.str.contains(name, na=False)\n",
    "    return data.loc[filt_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_name(data: pd.DataFrame, column: pd.Series, input_names: list[str]):\n",
    "    output_names = []\n",
    "    for name in input_names:\n",
    "        filter_data = check_name(data, column, name)\n",
    "        if len(filter_data) == 0 :\n",
    "            output_names  = output_names  + [name]\n",
    "        else:\n",
    "            continue\n",
    "    return output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filter_data_by_name(popSizeScania, popSizeScania['GEOIDNMN'], parishesScania_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data_by_name(parishScaniaMap, parishScaniaMap['G_NAME'], popSizeScania_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusScania = delete_strings(censusScania, 'GEOIDNMN',[', DEL KRISTIANSTAD'\n",
    "                                , 'PASTORAT'\n",
    "                                , ', DEL AV (FROSTA HÄRAD, MALMÖHUS LÄN)'\n",
    "                                , 'GARNISONSFÖRS.'\n",
    "                                , 'SLOTTSFÖRSAMLING'\n",
    "                                , '(MALMÖ SF)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check regular expressions code in Mathematica for eliminATING SOME STRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parishesScaniaNoPop = []\n",
    "\n",
    "for name in parishesScania_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        parishesScaniaNoPop  = parishesScaniaNoPop  + [name]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_name(popSizeScania, popSizeScania['GEOIDNMN'], 'YSTAD')\n",
    "check_name(popSizeScania, popSizeScania['GEOIDNMN'], 'OLOFS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(censusScania['GEOIDNMN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2 = popSizeScania['GEOIDNMN'].str.contains('NORRA RÖRUM', na=False)\n",
    "#popSizeScania.loc[filt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(popSizeScania[['GEOIDNMN','AR']].iloc[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
