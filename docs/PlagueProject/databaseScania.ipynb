{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python 3.11.2\n",
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import json # for pretty printing\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three different data sources. \n",
    "\n",
    "1. The data collected by Bodil corresponds to the plague period.\n",
    "2. The information from the TABVERK database includes the population size for parishes in the posterior years of the plague.\n",
    "3. The geographical information (polygons) for some parishes. This information doesn't correspond to the plague period.\n",
    "\n",
    "Our goal is to create a unique database for our project: Plague spread across Scania, Sweden, from 1710 to 1715."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For public files paths\n",
    "data_folder = \"data\"\n",
    "appendix6_path = os.path.join(data_folder, \"Appendix6Bodil.csv\")\n",
    "\n",
    "# For private files paths\n",
    "data_private_folder = \"data/private\"\n",
    "allParishes_path = os.path.join(data_private_folder, \"allParishesScania.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read the different data sources (.xlsx, .csv, and .shp files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bodil's data Appendix 6 plague parishes\n",
    "plagueParishesScania = pd.read_csv(appendix6_path, sep=\",\", encoding=\"utf-8\")\n",
    "# All parishes in Scania during the plague period\n",
    "allParishesScania = pd.read_excel(allParishes_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the lowercase to uppercase and checking the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allParishesScania = allParishesScania.apply(\n",
    "    lambda x: x.astype(str).str.upper())\n",
    "plagueParishesScania = plagueParishesScania.apply(\n",
    "    lambda x: x.astype(str).str.upper())\n",
    "type(plagueParishesScania)\n",
    "type(allParishesScania)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plagueParishesScania)\n",
    "#allParishesScania.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allParishesScania)\n",
    "#plagueParishesScania.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the two datasets (allParishesScania and plagueParishesScania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishesScania = pd.merge(\n",
    "    allParishesScania, plagueParishesScania, how='left', on=['ParishName', 'Region'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the new data frame keep all the outbreaks for parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>District(Härad)</th>\n",
       "      <th>ParishName</th>\n",
       "      <th>BeginPlaguePeriod</th>\n",
       "      <th>EndPlaguePeriod</th>\n",
       "      <th>VictimsNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>NORTHEAST</td>\n",
       "      <td>VILLANDS</td>\n",
       "      <td>NÄSUM</td>\n",
       "      <td>NOV 1710</td>\n",
       "      <td>APR 1711</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>NORTHEAST</td>\n",
       "      <td>VILLANDS</td>\n",
       "      <td>NÄSUM</td>\n",
       "      <td>FEB 1712</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Region District(Härad) ParishName BeginPlaguePeriod EndPlaguePeriod  \\\n",
       "393  NORTHEAST        VILLANDS      NÄSUM          NOV 1710        APR 1711   \n",
       "394  NORTHEAST        VILLANDS      NÄSUM          FEB 1712       UNDEFINED   \n",
       "\n",
       "    VictimsNumber  \n",
       "393           671  \n",
       "394             ?  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parishesScania.loc[parishesScania['ParishName'] == 'NÄSUM']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function for extracting the names of the parishes in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Names(data: pd.DataFrame, heading:str) -> list:\n",
    "    return data[heading]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parishesScania_names = get_Names(parishesScania, 'ParishName').unique().tolist()\n",
    "len(parishesScania_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of 'parishesScania_names' is less than the number of rows in the data frame 'allparishesScania'. This means, there is a repeated name: 'LÖDDEKÖPINGE'. We have to check the information for this parish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>District(Härad)</th>\n",
       "      <th>ParishName</th>\n",
       "      <th>BeginPlaguePeriod</th>\n",
       "      <th>EndPlaguePeriod</th>\n",
       "      <th>VictimsNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>HARJAGER</td>\n",
       "      <td>LÖDDEKÖPINGE</td>\n",
       "      <td>AUG 1712</td>\n",
       "      <td>DEC 1712</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>TORNA</td>\n",
       "      <td>LÖDDEKÖPINGE</td>\n",
       "      <td>AUG 1712</td>\n",
       "      <td>DEC 1712</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Region District(Härad)    ParishName BeginPlaguePeriod  \\\n",
       "87   SOUTHWEST        HARJAGER  LÖDDEKÖPINGE          AUG 1712   \n",
       "161  SOUTHWEST           TORNA  LÖDDEKÖPINGE          AUG 1712   \n",
       "\n",
       "    EndPlaguePeriod VictimsNumber  \n",
       "87         DEC 1712             ?  \n",
       "161        DEC 1712             ?  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parishesScania.loc[parishesScania['ParishName'] == 'LÖDDEKÖPINGE']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the parish LÖDDEKÖPINGE at HARJAGER was affected by the plague according to the file 'Bilaga 6 d - sydväst.doc' provided by Bodil. So we need to fix the information in the other row (161)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishesScania.at[161, 'BeginPlaguePeriod'] = np.NaN\n",
    "parishesScania.at[161, 'EndPlaguePeriod'] = np.NaN\n",
    "parishesScania.at[161, 'VictimsNumber'] = np.NaN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>District(Härad)</th>\n",
       "      <th>ParishName</th>\n",
       "      <th>BeginPlaguePeriod</th>\n",
       "      <th>EndPlaguePeriod</th>\n",
       "      <th>VictimsNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>HARJAGER</td>\n",
       "      <td>LÖDDEKÖPINGE</td>\n",
       "      <td>AUG 1712</td>\n",
       "      <td>DEC 1712</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>TORNA</td>\n",
       "      <td>LÖDDEKÖPINGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Region District(Härad)    ParishName BeginPlaguePeriod  \\\n",
       "87   SOUTHWEST        HARJAGER  LÖDDEKÖPINGE          AUG 1712   \n",
       "161  SOUTHWEST           TORNA  LÖDDEKÖPINGE               NaN   \n",
       "\n",
       "    EndPlaguePeriod VictimsNumber  \n",
       "87         DEC 1712             ?  \n",
       "161             NaN           NaN  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parishesScania.loc[parishesScania['ParishName'] == 'LÖDDEKÖPINGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the data frame by region and then get the names of the parishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishes = allParishesScania.loc[allParishesScania['Region'] == 'SOUTHEAST']\n",
    "southeastParishes_names = get_Names(southeastParishes, 'ParishName')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the census file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102360, 50)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the working directory for private files\n",
    "data_private_folder = \"data/private\"\n",
    "census_path = os.path.join(data_private_folder, 'FILE01_FALD.csv')\n",
    "censusSweden = pd.read_csv(census_path, sep=';')\n",
    "censusSweden.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusSweden.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the names of all columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = censusSweden.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the data only with specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusSweden = pd.read_csv(census_path, sep=';', usecols=[\n",
    "                           'LANGENNMN'  # Standard name of the county for the geographical area in plain text\n",
    "                           , 'GEOIDNMN'  # Standard name of the geographical area in plain text, i.e. not a source name\n",
    "                           , 'GEOIDTYP'  # Type of breakdown of the geographical area  0 =Assembly, 1 = Pastorate, 2 = Other type, 3 = Several parishes, 9 = Part of a parish\n",
    "                           , 'AR'  # Year\n",
    "                           , 'KON'  # 1 = Man  2 = Female. I choose 1 but it could be 2 for the total population\n",
    "                           , 'BEF_TOT'  # Total population at source\n",
    "                           , 'BEF_GENTOT'  # Total population, generated\n",
    "                           ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the census data such that corresponds only to Scania and the first population size registred for each parish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 7)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censusScania = censusSweden.loc[((censusSweden['LANGENNMN'] == 'KRISTIANSTADS LÄN') | (\n",
    "    censusSweden['LANGENNMN'] == 'MALMÖHUS LÄN')) & (censusSweden['KON'] == 1)]\n",
    "censusScania.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data: First, we remove given strings and white spaces at the end of a word. To do so, we must provide the string list to delete. In this step, you can use regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_strings(data: pd.DataFrame, name_column: str, list_expr: list[str]) -> pd.DataFrame:\n",
    "    for expr in list_expr:\n",
    "        data = data.apply(lambda x: x.replace({expr: ''}, regex=True))\n",
    "    data[name_column] = data[name_column].str.strip()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 7)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex to delete the following strings:\n",
    "# ', DEL (KRISTIANSTAD)', ', DEL (MALMÖHUS)', ', DEL (MALMÖHUS LÄN)'\n",
    "# ', DEL AV (FROSTA HÄRAD, MALMÖHUS LÄN)', ', DEL (EVERÖD, MALMÖHUS)'\n",
    "# ,' DEL (HYLLINGE, MALMÖHUS)', ' (MALMÖ SF)', '(STAFFANSTORP)'\n",
    "# ' GARNISONSFÖRS.', ' OCH GARNISONSFÖRS.', ' STADS', ' STAD'\n",
    "\n",
    "regex = r'\\s((OCH)?\\s+GARNISONSFÖRS.?| STADS?|(,\\sDEL(\\sAV)?)?\\s(((\\w+),?\\s)+))'                    \n",
    "\n",
    "censusScania_ = delete_strings(censusScania, 'GEOIDNMN', [\n",
    "                               'PASTORAT'\n",
    "                               , 'HOSPITAL'\n",
    "                               , ' LANDS'\n",
    "                               , ' SLOTTSFÖRSAMLING'\n",
    "                               , ' DOMKYRKOFÖRSAMLING'\n",
    "                               , regex\n",
    "                               ])\n",
    "censusScania.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data from Scania only to keep the first population size registered for each parish.\n",
    "This was done following two approaches. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First approach: We group the data by parish name and then select the minimum year. As the minimum year is not unique after deleted strings, this approach allows repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, groupby_column, year_column):\n",
    "    # Group a Pandas DataFrame by a column\n",
    "    parish_grp = df.groupby([groupby_column])\n",
    "    # Get the unique values of a column as a list\n",
    "    parish_grp_name = parish_grp[groupby_column].unique().tolist()\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for name in parish_grp_name:\n",
    "        grp_name = parish_grp.get_group(name[0])\n",
    "        result_df = pd.concat(\n",
    "            [result_df, (grp_name[grp_name[year_column] == grp_name[year_column].min()])], axis=0)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495, 7)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage example with the 'censusScania' dataframe\n",
    "popSizeScania = process_dataframe(censusScania, 'GEOIDNMN', 'AR')\n",
    "popSizeScania.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HELSINGBORGS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m popSizeScania\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mGEOIDNMN\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mget_group(\u001b[39m'\u001b[39;49m\u001b[39mHELSINGBORGS\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39m#popSizeScania.groupby(['GEOIDNMN']).size().to_csv('popSizeScania.csv', encoding='utf-8', index=True, header=True)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:817\u001b[0m, in \u001b[0;36mBaseGroupBy.get_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    815\u001b[0m inds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_index(name)\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(inds):\n\u001b[0;32m--> 817\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(name)\n\u001b[1;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HELSINGBORGS'"
     ]
    }
   ],
   "source": [
    "popSizeScania.groupby(['GEOIDNMN']).get_group('HELSINGBORGS')\n",
    "#popSizeScania.groupby(['GEOIDNMN']).size().to_csv('popSizeScania.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second approach: This method explores the given DataFrame exhaustively and keeps the required information in a dictionary. In our case, this information corresponds to the position associated with each parish name and the minimum year, according to the original DataFrame. This approach doesn't allow repetitions since the condition for replacing the information in the dictionary is strict (<)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "aux_dict = {}\n",
    "popSizeScania = pd.DataFrame() \n",
    "\n",
    "for i in range(len(censusScania)):\n",
    "    name_i = censusScania['GEOIDNMN'].iloc[i]\n",
    "    ar_i = censusScania['AR'].iloc[i]\n",
    "    if name_i in aux_dict:\n",
    "        if ar_i < aux_dict[name_i]['min']:\n",
    "            aux_dict[name_i] = {'min': ar_i, 'position': i}\n",
    "    else:\n",
    "        aux_dict[name_i] = {'min': ar_i, 'position': i}\n",
    "final_positions = [value['position'] for key, value in aux_dict.items()]\n",
    "popSizeScania = censusScania.iloc[final_positions]          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HELSINGBORGS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m popSizeScania\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mGEOIDNMN\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mget_group(\u001b[39m'\u001b[39;49m\u001b[39mHELSINGBORGS\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:817\u001b[0m, in \u001b[0;36mBaseGroupBy.get_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    815\u001b[0m inds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_index(name)\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(inds):\n\u001b[0;32m--> 817\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(name)\n\u001b[1;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HELSINGBORGS'"
     ]
    }
   ],
   "source": [
    "popSizeScania.groupby(['GEOIDNMN']).get_group('HELSINGBORGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(data: pd.DataFrame, heading: str, name: str):\n",
    "    filt_name = data[heading].str.contains(name, na=False)\n",
    "    return data.loc[filt_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Levenshtein import distance as levenshtein_distance\n",
    "levenshtein_distance('HÖRBYS', 'HÖRBY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_name(data: pd.DataFrame, heading: str, input_names: list[str]):\n",
    "    output_names = []\n",
    "    for name in input_names:\n",
    "        filter_data = check_name(data, heading, name)\n",
    "        if len(filter_data) == 0 :\n",
    "            output_names  = output_names  + [name]\n",
    "        else:\n",
    "            continue\n",
    "    return output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANGENNMN</th>\n",
       "      <th>GEOIDNMN</th>\n",
       "      <th>GEOIDTYP</th>\n",
       "      <th>AR</th>\n",
       "      <th>KON</th>\n",
       "      <th>BEF_TOT</th>\n",
       "      <th>BEF_GENTOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44416</th>\n",
       "      <td>KRISTIANSTADS LÄN</td>\n",
       "      <td>TJÖRNARP</td>\n",
       "      <td>0</td>\n",
       "      <td>1775</td>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LANGENNMN  GEOIDNMN  GEOIDTYP    AR  KON  BEF_TOT  BEF_GENTOT\n",
       "44416  KRISTIANSTADS LÄN  TJÖRNARP         0  1775    1      456         456"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popSizeScania_names = get_Names(popSizeScania, 'GEOIDNMN')\n",
    "check_name(popSizeScania, 'GEOIDNMN', 'TJÖRNARP')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the geographical information by parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "data_folder = \"MapScaniaSweden\"\n",
    "parishScania_path = os.path.join(data_folder, \"Parishes1720_1890.shp\")\n",
    "\n",
    "parishScaniaMap = gpd.read_file(parishScania_path)\n",
    "selected_columns = ['G_NAME','GET_END_YE', 'geometry']\n",
    "parishScaniaMap = parishScaniaMap[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishScaniaMap = delete_strings(\n",
    "    parishScaniaMap, ['FÖRSAMLING'\n",
    "                      , 'L LÄN'\n",
    "                      , 'S LÄN'\n",
    "                      , 'M LÄN'\n",
    "                      , 'HELIGA TREFALDIGHETS'\n",
    "                      , ' LANDSFÖRSAMLING'\n",
    "                      , ' STADS'\n",
    "                      , ' LANDS'\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "aux_dict = {}\n",
    "parishMap = gpd.GeoDataFrame() \n",
    "\n",
    "for i in range(len(parishScaniaMap)):\n",
    "    name_i = parishScaniaMap['G_NAME'].iloc[i]\n",
    "    ar_i = parishScaniaMap['GET_END_YE'].iloc[i]\n",
    "    if name_i in aux_dict:\n",
    "        if ar_i < aux_dict[name_i]['min']:\n",
    "            aux_dict[name_i] = {'min': ar_i, 'position': i}\n",
    "    else:\n",
    "        aux_dict[name_i] = {'min': ar_i, 'position': i}\n",
    "final_positions = [value['position'] for key, value in aux_dict.items()]\n",
    "parishMap = parishScaniaMap.iloc[final_positions]   \n",
    "print(parishMap.shape)            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishMap['G_NAME'][parishMap['G_NAME'] == 'TRELLEBORGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(13,10))\n",
    "parishMap.plot(ax=ax, column = \"G_NAME\", edgecolor='black', legend=False)\n",
    "plt.xlabel('Meters')\n",
    "plt.ylabel('Meters')\n",
    "# legend = ax.get_legend()\n",
    "# legend.set_bbox_to_anchor((1, 0.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parishMap_names = get_Names(parishMap, 'G_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SANKT OLOF',\n",
       " 'YSTAD SANKT PETRI',\n",
       " 'YSTAD SANKT MARIA',\n",
       " 'JERRESTAD',\n",
       " 'SKÖRUP',\n",
       " 'LILLA HARRIE ',\n",
       " 'ÖRTOFTA ',\n",
       " 'MALMÖ CAROLI',\n",
       " 'MALMÖ GARNISONEN',\n",
       " 'MALMÖ SANKT PETRI',\n",
       " 'MELLANGREVIE',\n",
       " 'SÄRLÖV',\n",
       " 'VÄSTRA KÄRRSTORP ',\n",
       " 'STORA SLÅGARP ',\n",
       " 'TRELLEBORG ',\n",
       " 'VELLINGE ',\n",
       " 'VÄSTRA ALSTAD ',\n",
       " 'VÄSTRA TOMMARP ',\n",
       " 'VÄSTRA VEMMERLÖV ',\n",
       " 'BONDERUP ',\n",
       " 'FLÄDIE ',\n",
       " 'NORRA NÖBBELOV',\n",
       " 'HASSLE BÖSARP',\n",
       " 'KÄLLSTORP ',\n",
       " 'LILLA ISIE ',\n",
       " 'SIMLINGE ',\n",
       " 'SÖDRA ÅBY ',\n",
       " 'ÄSPÖ ',\n",
       " 'ÖSTRA KLAGSTORP ',\n",
       " 'ÖSTRA TORP ',\n",
       " 'SÖDRA RÖRUM ',\n",
       " 'ÖSTRA SALLERUP ',\n",
       " 'ÖSTRA STRÖ ',\n",
       " 'ÖSTRA ÄSPINGE ',\n",
       " 'LÅNGARÖD',\n",
       " 'TOLÅNGA ',\n",
       " 'BÅSTAD ',\n",
       " 'HJÄRNARP ',\n",
       " 'VÄSTRA KARUP ',\n",
       " 'NORRA VRAM ',\n",
       " 'VÄLLUV ',\n",
       " 'VÄSBY ',\n",
       " 'FÄRINGTOFTA ',\n",
       " 'GRÅMANTORP',\n",
       " 'MUNKA LJUNGBY ',\n",
       " 'TÅSTARP ',\n",
       " 'ÖRKELLJUNGA ',\n",
       " 'ANNELÖV ',\n",
       " 'KÄLLS NÖBBELÖV ',\n",
       " 'NÄS – SE GULLARP ',\n",
       " 'VÄSTRA STRÖ ',\n",
       " 'ÖSTRA KARABY ',\n",
       " 'SIREKÖPINGE ',\n",
       " 'ST IBB',\n",
       " 'TOFTA ',\n",
       " 'HUARÖD ',\n",
       " 'LINDERÖD ',\n",
       " 'MAGLEHEM ',\n",
       " 'ÄSPHULT ',\n",
       " 'ÖSTRA SÖNNARSLÖV ',\n",
       " 'IGNABERNA',\n",
       " 'NORRA SANDBY',\n",
       " 'STOBY',\n",
       " 'EMITSLÖV',\n",
       " 'HJÄRSÅS',\n",
       " 'KNISLINGE',\n",
       " 'GUALÖV',\n",
       " 'VIBY',\n",
       " 'VÄSTRA LJUNGBY',\n",
       " 'VÄSTRA LJUNGBY']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_data_by_name(popSizeScania, 'GEOIDNMN', parishesScania_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_data_by_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filter_data_by_name(parishScaniaMap, parishScaniaMap[\u001b[39m'\u001b[39m\u001b[39mG_NAME\u001b[39m\u001b[39m'\u001b[39m], popSizeScania_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_data_by_name' is not defined"
     ]
    }
   ],
   "source": [
    "filter_data_by_name(parishScaniaMap, parishScaniaMap['G_NAME'], popSizeScania_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southeastParishesNoPop = []\n",
    "\n",
    "for name in southeastParishes_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        southeastParishesNoPop = southeastParishesNoPop + [name]\n",
    "    else:\n",
    "        continue\n",
    "    #print(southeastParishesNoPop)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check regular expressions code in Mathematica for eliminATING SOME STRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parishesScaniaNoPop = []\n",
    "\n",
    "for name in parishesScania_names:\n",
    "    filter_data = check_name(popSizeScania, popSizeScania['GEOIDNMN'], name)\n",
    "    if len(filter_data) == 0 :\n",
    "        parishesScaniaNoPop  = parishesScaniaNoPop  + [name]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_name(popSizeScania, popSizeScania['GEOIDNMN'], 'YSTAD')\n",
    "check_name(popSizeScania, popSizeScania['GEOIDNMN'], 'OLOFS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(censusScania['GEOIDNMN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2 = popSizeScania['GEOIDNMN'].str.contains('NORRA RÖRUM', na=False)\n",
    "#popSizeScania.loc[filt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(popSizeScania[['GEOIDNMN','AR']].iloc[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
